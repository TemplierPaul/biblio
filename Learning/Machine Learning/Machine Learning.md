# Machine Learning

Tags: #ML #interview-prep

## Deep Learning Fundamentals

### Neural Architectures
- [[Transformer|Transformer]] - Attention-based architecture that revolutionized NLP
- [[Attention|Attention Mechanism]] - Core mechanism for selective focus
- [[LSTM|LSTM]] - Recurrent architecture for sequences
- [[GNN|Graph Neural Networks]] - Learning on graph-structured data

### Transformers & Language Models
- [[LLMs|Large Language Models]] - Pre-training, scaling, and capabilities
- [[Masking|Masking]] - Causal, padding, and MLM strategies

### Model Training & Adaptation
- [[Fine-tuning|Fine-tuning]] - Adapting pre-trained models to new tasks
- [[LoRA|LoRA]] - Parameter-efficient fine-tuning
- [[RLHF|RLHF]] - Alignment through human feedback

### Generative Models
- [[Diffusion|Diffusion Models]] - State-of-the-art image generation

### Classical ML
- [[Gaussian-Processes|Gaussian Processes]] - Bayesian non-parametric regression

### Applications
- [[VLA|Vision-Language-Action (RT-2)]] - Foundation models for robotics

## Key Concepts
- Supervised Learning
- Unsupervised Learning
- Deep Learning
